ПІДГОТОВКА ТА АНАЛІЗ ДЖЕРЕЛ ФІНАНСОВИХ ДАНИХ, ЯК ПОЧАТКОВИЙ ЕТАП СТОХАСТИЧНОГО МОДЕЛЮВАННЯ ЧАСОВИХ РЯДІВ МЕТОДАМИ МАШИННОГО НАВЧАННЯ
 
Метою даної роботи є визначення ключових компонентів дослідницького середовища для застосування методів машинного навчання у стохастичному моделюванні фінансових часових рядів, із фокусом на аналізі відомих світових джерел фінансових стохастичних даних та демонстрації можливостей їх опрацювання за допомогою програмних платформ з інтегрованим інструментарієм машинного навчання. 
Ключові слова: стохастичні числові ряди, ринкові котирування, платформи Kaggle, Huggingface, Yahoo!Finance, MATLAB, Python, Random Forest, імпутація, ROC, AUC, точність класифікації (Accuracy), достовірність позитивного прогнозу (Precision), середня абсолютна помилка (MAE), середня абсолютна відсоткова помилка(MAPE), середня квадратична помилка (MSE).
Постановка проблеми. Завдання створення дослідницького середовища для розроблення та оцінювання методів машинного навчання, застосовуваних до стохастичного моделювання часових рядів фінансової природи. На думку авторів, таке середовище повинно включати низку ключових компонентів: 
1.	Джерела вхідних даних, що охоплюють:
а) «сирі» дані реальних фінансових систем (ринкові котирування, біржові індикатори, макроекономічні показники тощо);
б) спеціально підготовлені датасети, сформовані на базі відкритих платформ і репозитаріїв для задач машинного навчання.
2.	Програмну платформу для моделювання, бажано з вбудованим інструментарієм машинного навчання, що забезпечує можливість передобробки даних, побудови моделей та проведення експериментів.
Систему критеріїв оцінювання моделей, яка включає:
а) внутрішні метрики (релевантні показники якості моделі машинного навчання);
б) зовнішні критерії, що передбачають бенчмаркінг та порівняння з існуючими підходами та еталонними моделями.
У межах даної доповіді основна увага зосереджується на аналізі джерел вхідних даних, а також у якості прикладів роботи з джерелами виконано застосування базового загальновідомого алгоритму машинного навчання Random Forest до двох джерел даних в різних програмних середовищах з інструментарієм машинного навчання.

Базою стохастичного моделювання в фінансовій сфері є дані у вигляді часових рядів. Часовий ряд – це сукупність спостережень, зроблених послідовно протягом певного часу. Якщо майбутні значення можна точно передбачити на основі минулих значень, то ряд називається детермінованим. Однак більшість рядів є стохастичними або випадковими, оскільки майбутнє лише частково визначається минулими значеннями[1]. Особливо це стосується часових рядів в фінансовій сфері, ринкові дані в більшості є стохастичними часовими рядами.
У якості джерел вхідних даних для дослідження числових рядів з фінансової сфери за допомогою методів машинного навчання на автори пропонують :
1.	Платформи постачання ринкових фінансових даних (Financial Market Data Providers / APIs) - джерела первинних фінансових часових рядів, наприклад: 
•	Financial Modeling Prep (FMP) – безкоштовне джерело первинної ринкової інформації,
•	Yahoo ! Finance – безкоштовне джерело первинної ринкової інформації,
•	NYSE API – платний API до Нью-Йоркської фондової біржі.
Платформи надають сирі ринкові дані, що є джерелом реальних часових рядів, наприклад FMP: часові ряди цін закриття, відкриття, миттєвих, максимумів, мінімумів та обсягів торгівлі фінансовими інструментами тощо. Ці платформи або мають описані в документації інтерфейси, або, як Yahoo Finance, що є одним з найвідоміших безкоштовних джерел фінансової інформації – open-source інтерфейс на мові Python.
2.	Платформи відкритих датасетів для машинного навчання (Open ML Dataset Platforms) - джерела вторинних (підготовлених) даних для машинного навчання. Це ресурси, що надають готові датасети, сформовані, очищені або анотовані для ML-задач:
•	Hugging Face – світова база датасетів та моделей машинного навчання;
•	Kaggle – база датасетів  та площадка світових змагань між моделями.
На відміну від платформ постачання первинних фінансових даних, ресурси типу Hugging Face та Kaggle характеризуються не лише наявністю «сирих» часових рядів, але й широким спектром вторинних, спеціально підготовлених датасетів у форматі “features + target”.  Датасети вже структуровані таким чином, що кожен рядок відповідає окремому об’єкту спостереження та містить готові ознаки (фічі) і цільову змінну, що суттєво спрощує їх безпосереднє використання в моделях машинного навчання без додаткових етапів масштабної препроцесінгової роботи. Крім того, значна частина датасетів супроводжується прикладами моделей, кодом експериментів та посиланнями на наукові публікації, що досліджують відповідні дані, що підвищує їхню методологічну цінність для науковців. Особливої уваги заслуговує платформа Kaggle, яка функціонує як глобальне середовище змагань між ML-моделями: учасникам пропонується датасет і чітко визначена ціль прогнозування, а результати оцінюються за формалізованими метриками якості. За перші позиції у рейтингу передбачені грошові винагороди, що стимулює розвиток нових підходів і сприяє появі висококонкурентних моделей. Велика колекція економічних датасетів проаналізована і зібрана в Table 2 [2]. Тут можна побачити, що кожен датасет створений для певних задач машинного навчання (стовпець Task) – автори згрупували та завдання у вісім аспектів і проставили навпроти кожного датасету відповідний аспект:
•	аналіз тексту (TA): наприклад, аналіз настроїв (sentiment analysis) фінансових новин;
•	прогнозування (FO): наприклад, прогнозування руху цін на акції,
тощо.
Враховуючи вищезазначену класифікацію джерел даних виконано два експерименти.
Експеримент №1 : дослідження роботи з датасетом HMEQ, розташованому на платформі Kaggle. Основна задача : пройти всі етапи формування моделі машинного навчання та етапи аналізу результатів роботи моделі, використовуючи інструментарій платформи MATLAB R2025b та порівняти створену модель з найкращими моделями, що застосовуються по цьому напрямку – прогнозуванню дефолтів. Датасет містить дані щодо характеристик та історії кредитів, а також ознаку дефолту позичальника. Основна мета цього датасету — надати інформацію для побудови моделі, яка прогнозує ймовірність дефолту клієнта, тобто вирішення задачі бінарної класифікації. У якості програмної платформи для дослідження вибраний MATLAB R2025b. У рамках дослідження застосовано алгоритм дерева рішень (Decision Tree) як базовий метод класифікації. Дерево рішень особливо підходить до задачі кредитного скорингу, оскільки забезпечує не лише високу точність, а й інтерпретованість результатів, що є критично важливим для фінансових рішень. Алгоритм дозволяє формувати послідовні правила прийняття рішення на основі багатьох фінансових ознак, виділяти ключові фактори ризику та наочно пояснювати причини віднесення клієнта до категорії дефолтних. Саме тому Decision Tree обрано як метод, оптимально поєднуючий прогностичну силу й прозорість моделі для завдань кредитного ризику.
Кожний рядок датасету HMEQ з точки зору машинного навчання є окремим прикладом або інстансом — тобто унікальним записом, що містить опис одного кредитного випадку з відповідними ознаками позичальника та фінансової історії. Такий підхід дозволяє алгоритму машинного навчання вчитися на множині випадків і прогнозувати результат (наприклад, дефолт чи його відсутність) на основі наявних ознак. Первинний аналіз датасету виявив наявність порожніх (відсутніх) значень у ряді стовпців, зокрема у MORTDUE, що типово для фінансових даних. Для коректної роботи алгоритмів ML необхідно виконувати процедуру заповнення пропущених даних (імпутації). Основні методи імпутації в ML — це заміна порожніх значень на середнє, медіану, моду, інтерполяцію або рухоме середнє. У середовищі MATLAB ця задача легко вирішується, зокрема для стовпця MORTDUE використано команду:data.MORTDUE = fillmissing(data.MORTDUE, 'movmean', 5), що реалізує імпутацію методом рухомого середнього для послідовних пропущених даних - кожне пропущене значення заміниться на середнє з п’яти сусідніх значень навколо нього (включаючи наявні зліва і справа у межах вікна шириною 5). Таким чином, якісна підготовка даних є важливою складовою побудови ефективних ML-моделей. 
В ході експерименту [7] виконуються стандартні для методів машинного навчання кроки : визначення цільової змінної(target), відділення ознак від цільової змінної (фічі), розподіл на тренувальну (70%) і тестову (30%) вибірки, навчання моделі дерева рішень, прогнозування на тестовій вибірці, обчислення точності моделі, вивід матриці плутанини, обчислення основних метрик класифікації, побудова ROC-кривої похибок. Матриця плутанини порівнює реальні (фактичні) значення з прогнозованими, відображаючи кількість правильних і неправильних класифікацій для кожного класу. Для задачі кредитного скорингу (виявлення дефолтних клієнтів) матриця плутанини є дуже показовою, оскільки дозволяє чітко побачити, скільки дефолтних кредитів модель виявила правильно, а скільки пропустила чи неправильно віднесла до недефолтних, і навпаки.
Модель дерева рішень для задачі прогнозування дефолту клієнтів показала такі результати:
точність класифікації становить 86.35%, тобто більшість прикладів були класифіковані вірно. В цілому метрики свідчать про відносно рівномірну якість класифікації, модель не схильна ні до пропуску великої кількості дефолтів, ні до надмірно широкої групи ризику. ROC-крива для побудованої моделі знаходиться вище діагоналі випадкового класифікатора, площа під кривою (AUC) — 0.780. Це вказує на добру здатність моделі розділяти дефолтних і недефолтних клієнтів. Значення AUC > 0.7 традиційно вважається хорошим і відображає якісне розпізнавання кредитного ризику для обраної моделі. 
Порівнюючи отриману модель з топовими SOTA (State-of-the-Art)-моделями для задачі прогнозування дефолту на HMEQ (і подібних фінансових датасетах) треба сказати, що останні мають суттєві переваги над класичними деревами рішень, так в  [8] в  Table. 1. Model Evaluation Results for Loan Prediction :  Точність класифікації (Accuracy) та Достовірність позитивного прогнозу (Precision) всіх моделей  більше 90%, що значно краще, ніж в моделі, побудованої в ході експерименту. Порівняння результатів показує, що для досягнення рівня SOTA-моделей у задачі прогнозування дефолту доцільно рухатись у напрямку використання ансамблевих алгоритмів, глибокого навчання та розширеного балансування класів для істотного підвищення показників якості моделі.
Експеримент №2 : дослідження джерела даних  Yahoo!Finance.  Основна задача : оцінка можливостей використання сирих ринкових даних, отриманих із платформи Yahoo!Finance, для задач ML з використанням відкритого API "yfinance"(Python). Джерелом аналізу є "сирі дані" - історичні часові ряди цін акцій, які містять інформацію про ціну відкриття (Open), найвищу ціну дня (High), найнижчу ціну дня (Low), ціну закриття (Close), торгові обсяги (Volume) для обраного фінансового інструменту, зокрема Apple .
У рамках експерименту було сформовано модель машинного навчання, яка навчається на п’ятихвилинних інтервалах цін акцій за один торговий день (інтраденні дані). Тестування моделі здійснюється на окремому періоді — останні 2 години сесії (24 інтервали по 5 хвилин), що дозволяє об’єктивно оцінити якість та прикладну цінність алгоритму для короткострокових фінансових прогнозів. Такий підхід дає змогу проаналізувати ефективність роботи із сирими фінансовими даними Yahoo!Finance, їхню структуру, якість, а також перспективи застосування у наукових і практичних задачах часових рядів. Для цієї задачі використовується алгоритм RandomForest, що дозволяє враховувати складні нелінійні взаємозв’язки у фінансовому ряді.
Дані Yahoo!Finance є «сирими» часовими рядами, тому перед використанням у моделі Random Forest їх необхідно самостійно перетворити на повноцінний навчальний датасет: були створені лагові ознаки – тобто нові стовпці, що містять значення ціни закриття за попередні 5-хвилинні інтервали (lag_1, lag_2, …), сформовані шляхом зсуву колонки Close назад у часі. Далі було визначено цільову змінну як фактичну ціну закриття наступного інтервалу, отриману через зсув Close на один крок уперед (shift(-1)). Після видалення пропусків сформовані матриця ознак (X) і цільовий стовпець (y) стали основою для навчання моделі RandomForestRegressor.
Якості моделі оцінюють за основними метриками для регресійних задач часових рядів: MAE (Mean Absolute Error), MAPE (Mean Absolute Percentage Error) та MSE (Mean Squared Error). Вибір цих метрик обґрунтований їх прикладною інтерпретацією у фінансовій аналітиці: MAE характеризує середню похибку у доларах, MAPE — середній відсоток помилки, що дозволяє оцінити узгодженість прогнозу незалежно від масштабу, а MSE чутливий до значних промахів, що критично для ризик-менеджменту та оцінки надійності моделі. Такі метрики широко застосовуються у наукових роботах з фінансового регресійного прогнозування як найбільш інформативні щодо якості моделі.
Аналіз отриманих результатів експерименту підтверджує високу зручність та практичність використання сервісу Yahoo!Finance як джерела для збору інтраденних котирувань акцій Apple. Дані легко інтегруються у сучасні програмні середовища, мають стандартизовану структуру, що суттєво спрощує підготовку вибірки і дозволяє автоматизувати процес побудови ознак. Застосовність таких даних у експериментах з машинного навчання оцінюється як висока: часові ряди мають достатню роздільність і актуальність для моделювання короткострокових динамік, ключових для фінансового прогнозування. Оцінка якості побудованої регресійної моделі показала низькі значення MAE, MAPE та MSE, як у межах крос-валідації, так і на нового тестового періоду, що свідчить про ефективність обраних алгоритмів і дозволяє розглядати отриману модель як надійний інструмент для практичного застосування у фінансовій аналітиці та наукових дослідженнях.
Варто зазначити, що фінансові часові ряди, мають стохастичну природу, що підтверджується численними теоретичними і практичними дослідженнями[1,9]. Характеристики розподілу фінансових рядів можуть змінюватися в кожен окремий період, а закони їх еволюції нерідко підпорядковуються складним випадковим процесам. Відповідно, не існує універсальної моделі, яка гарантовано забезпечить високу якість прогнозів для будь-якого дня чи інструменту. Зміна волатильності, структурних зрушень чи інтервенцій ринку може призвести до того, що попередньо натренована модель втратить актуальність. Таким чином, отримані результати слід аналізувати в контексті обмежень і стохастичності фінансових рядів; модель може бути ефективною лише за умови релевантності навчальних даних поточному ринковому стану.
Висновки. У роботі було проведено два експерименти, які показали, що вибір джерела даних і програмного середовища суттєво впливає на побудову моделей машинного навчання. У Експерименті №1 використовувався готовий датасет HMEQ на платформі Kaggle та середовище MATLAB. Завдяки тому, що дані вже були підготовлені, модель Decision Tree вдалося швидко побудувати й оцінити. MATLAB виявився зручним інструментом, оскільки має вбудовані засоби для обробки даних, навчання моделей і перегляду результатів.
У Експерименті №2 застосовувалась мова Python і сирі дані Yahoo!Finance про інтраденні ціни акцій Apple. Тут потрібно було самостійно створювати ознаки та готувати дані, але Python надав потужні інструменти для роботи з часовими рядами та побудови моделі Random Forest. Отримані результати показали, що такі дані можна використовувати для короткострокових фінансових прогнозів.
У підсумку: підготовлені датасети (як у MATLAB) підходять для швидкого навчання й аналізу моделей, а сирі ринкові дані (як у Python) дозволяють працювати ближче до реальних умов, але потребують більше обробки. Обидва підходи корисні, а MATLAB і Python забезпечують зручний і сучасний інструментарій для досліджень у сфері машинного навчання та фінансових часових рядів.

